{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HAM10000 Skin Cancer Classifier – End-to-End Training\n",
        "\n",
        "This Colab notebook builds a production-ready skin cancer classifier using the HAM10000 dataset. It covers environment setup, data ingestion and cleaning, imbalance-aware training with EfficientNetB0, rich evaluation (accuracy, confusion matrix, classification report, ROC curves), and artifact export (`model.h5`, `label_map.json`, and a reusable preprocessing script)."
      ],
      "id": "eca79fe6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Dependencies\n",
        "- Run the cell below once per runtime to install all required packages.\n",
        "- Provide your Kaggle API token (`kaggle.json`) when prompted so that the notebook can download HAM10000 automatically.\n",
        "- Make sure you have at least 20GB of free disk space."
      ],
      "id": "51cf41f7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q kaggle pandas scikit-learn seaborn matplotlib tensorflow==2.13.0 tensorflow-addons tensorflow-io pillow albumentations --upgrade"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "80ad1656"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             ConfusionMatrixDisplay, roc_curve, auc, recall_score)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "DATASET_DIR = Path('/content/HAM10000')\n",
        "EXPORT_DIR = Path('/content/drive/MyDrive/skin-cancer-artifacts')\n",
        "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        ""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f06ba637"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Connect Google Drive"
      ],
      "id": "3891edf3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9a504a7a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download HAM10000 from Kaggle\n",
        "Upload your `kaggle.json` (Account → Create API Token) using the file picker. The cell will handle installing the CLI, configuring credentials, and extracting the dataset."
      ],
      "id": "0432c83b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import files\n",
        "\n",
        "if not Path('kaggle.json').exists():\n",
        "    print('Upload kaggle.json (download from https://www.kaggle.com/ -> Account)')\n",
        "    uploaded = files.upload()\n",
        "    if 'kaggle.json' not in uploaded:\n",
        "        raise RuntimeError('kaggle.json is required!')\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "if not DATASET_DIR.exists():\n",
        "    DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    !kaggle datasets download -d kmader/skin-cancer-mnist-ham10000 -p /content/HAM10000\n",
        "    !unzip -oq /content/HAM10000/skin-cancer-mnist-ham10000.zip -d /content/HAM10000\n",
        "\n",
        "metadata_path = DATASET_DIR / 'HAM10000_metadata.csv'\n",
        "assert metadata_path.exists(), 'Metadata CSV missing – check Kaggle download.'"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a72b19df"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Loading, Cleaning, and Label Encoding"
      ],
      "id": "5afd476b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "metadata = pd.read_csv(metadata_path)\n",
        "print(f\"Raw metadata rows: {len(metadata):,}\")\n",
        "\n",
        "# Handle missing values\n",
        "default_age = metadata['age'].median()\n",
        "metadata['age'] = metadata['age'].fillna(default_age)\n",
        "metadata['sex'] = metadata['sex'].fillna('unknown')\n",
        "metadata['localization'] = metadata['localization'].fillna('unknown')\n",
        "metadata['dx_type'] = metadata['dx_type'].fillna('unknown')\n",
        "\n",
        "# Merge with file paths\n",
        "image_dirs = [DATASET_DIR / 'HAM10000_images_part_1', DATASET_DIR / 'HAM10000_images_part_2']\n",
        "image_records = []\n",
        "for img_dir in image_dirs:\n",
        "    for img_path in img_dir.glob('*.jpg'):\n",
        "        image_records.append({'image_id': img_path.stem, 'file_path': img_path.as_posix()})\n",
        "paths_df = pd.DataFrame(image_records)\n",
        "\n",
        "metadata = metadata.merge(paths_df, how='inner', on='image_id')\n",
        "print(f\"Metadata rows after merge: {len(metadata):,}\")\n",
        "\n",
        "metadata.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "aecf40bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "label_encoder = LabelEncoder()\n",
        "metadata['label_idx'] = label_encoder.fit_transform(metadata['dx'])\n",
        "class_names = list(label_encoder.classes_)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "label_map = {int(idx): name for idx, name in enumerate(class_names)}\n",
        "print('Classes:', label_map)\n",
        ""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "baba1646"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df, temp_df = train_test_split(\n",
        "    metadata,\n",
        "    test_size=0.3,\n",
        "    stratify=metadata['label_idx'],\n",
        "    random_state=SEED\n",
        ")\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df['label_idx'],\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4b3e44c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Pipeline, Augmentation, and Class Weights"
      ],
      "id": "590cc68d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_aug = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.7, 1.3]\n",
        ")\n",
        "val_aug = ImageDataGenerator(rescale=1./255)\n",
        "test_aug = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_aug.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='file_path',\n",
        "    y_col='dx',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "val_gen = val_aug.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='file_path',\n",
        "    y_col='dx',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "test_gen = test_aug.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='file_path',\n",
        "    y_col='dx',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_df['dx']),\n",
        "    y=train_df['dx']\n",
        ")\n",
        "label_to_index = train_gen.class_indices\n",
        "weights_by_index = {label_to_index[label]: weight for label, weight in zip(np.unique(train_df['dx']), class_weights)}\n",
        "weights_by_index"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9b471ef7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Architecture – EfficientNetB0 Transfer Learning"
      ],
      "id": "11a01d04"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "base_model = EfficientNetB0(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(*IMAGE_SIZE, 3)\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = layers.Input(shape=(*IMAGE_SIZE, 3), name='input_image')\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs, name='ham10000_efficientnetb0')\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "7b48c5c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training with EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
      ],
      "id": "f970b538"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "checkpoint_path = EXPORT_DIR / 'model-best.h5'\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-6),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path.as_posix(), monitor='val_loss', save_best_only=True)\n",
        "]\n",
        "\n",
        "epochs = 30\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_gen,\n",
        "    class_weight=weights_by_index,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "87fd843e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional Fine-Tuning\n",
        "Unfreeze the last 50 layers of EfficientNetB0 for a short fine-tuning stage once the top classifier converges."
      ],
      "id": "8f5a38e2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for layer in base_model.layers[-50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=10,\n",
        "    validation_data=val_gen,\n",
        "    class_weight=weights_by_index,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "789b48c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluation – Accuracy, Classification Report, Per-Class Recall"
      ],
      "id": "29b95352"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_loss, test_acc = model.evaluate(test_gen, verbose=1)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Collect predictions\n",
        "probs = model.predict(test_gen)\n",
        "y_pred = np.argmax(probs, axis=1)\n",
        "y_true = test_gen.classes\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "print(json.dumps(report, indent=2))\n",
        "\n",
        "per_class_recall = {class_names[i]: recall_score(y_true == i, y_pred == i) for i in range(num_classes)}\n",
        "print('Per-class recall:', per_class_recall)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d64525ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
        "plt.title('HAM10000 Confusion Matrix')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ee09748f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. ROC Curves"
      ],
      "id": "2b9a144b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "y_true_binarized = label_binarize(y_true, classes=list(range(num_classes)))\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "for idx, class_name in enumerate(class_names):\n",
        "    fpr, tpr, _ = roc_curve(y_true_binarized[:, idx], probs[:, idx])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    ax.plot(fpr, tpr, label=f\"{class_name} (AUC={roc_auc:.3f})\")\n",
        "ax.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('Per-Class ROC Curves')\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1e167ddf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Export Artifacts (`model.h5`, `label_map.json`, `preprocess.py`)\n",
        "The exported files live in Google Drive so they can be downloaded, versioned, or synced into your deployment repository."
      ],
      "id": "84f3d020"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_path = EXPORT_DIR / 'ham10000_effnetb0.h5'\n",
        "label_map_path = EXPORT_DIR / 'label_map.json'\n",
        "preprocess_path = EXPORT_DIR / 'preprocessing.py'\n",
        "\n",
        "model.save(model_path)\n",
        "print('Saved model to', model_path)\n",
        "\n",
        "with open(label_map_path, 'w') as f:\n",
        "    json.dump({\"index_to_label\": label_map, \"label_to_index\": {v: k for k, v in label_map.items()}}, f, indent=2)\n",
        "print('Saved label map to', label_map_path)\n",
        "\n",
        "preprocess_script = f'''from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "IMAGE_SIZE = {IMAGE_SIZE}\n",
        "\n",
        "\n",
        "def load_image(image_path_or_bytes):\n",
        "    \"\"\"Load an image from disk or a BytesIO stream and convert to RGB.\"\"\"\n",
        "    if hasattr(image_path_or_bytes, 'read'):\n",
        "        image = Image.open(image_path_or_bytes)\n",
        "    else:\n",
        "        image = Image.open(Path(image_path_or_bytes))\n",
        "    return image.convert('RGB')\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Resize to 224x224 and normalize to [0, 1].\"\"\"\n",
        "    image = image.resize(IMAGE_SIZE)\n",
        "    arr = np.asarray(image).astype('float32') / 255.0\n",
        "    return np.expand_dims(arr, axis=0)\n",
        "'''\n",
        "with open(preprocess_path, 'w') as f:\n",
        "    f.write(preprocess_script)\n",
        "print('Saved preprocessing helper to', preprocess_path)\n",
        ""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "08a19e63"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✅ **Next steps**: download the three exported files and copy them into the repository's `model/` directory (or mount from cloud storage) so the Flask API can load them for inference."
      ],
      "id": "dbef1f87"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}